{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ab873bbe",
   "metadata": {},
   "source": [
    "# Vocoders \n",
    "\n",
    "\n",
    "Vocoders (Voice coders) originated from the early days of speech signal processing. The main idea is to break the spectrum into subbands and then analyze each subband to extract information about it (in early vocoders just \n",
    "the energy in each subband). For each short frame of audio (typically 10-50 milliseconds) one calculates the gain for each subband, plus a pitch/noise + power for an artificial source that is either noise to encode consonants or a pitched oscillator (to encode vowels). So if we have something like 40 frames per second and each frame consists of 8 subband gains and a pitch estimate + noise power level we have something like 400 numbers per second instead of 8000 or 16000 numbers per second which are common rates for speech. The resynthesized speech sounds artificial and robotic but is still intelligible. \n",
    "\n",
    "In the 1970s-80s musicians started using cross-synthesis vocoders that replaced the synthetic parametric source with an rich spectral signal - for example one can feed speech to the vocoder analysis filterbank and a distorted electric guitar into the sysnthesis bank audio inputs. \n",
    "\n",
    "One can view a discrete fourier transform (DFT) as a way to perform a filterbank decomposition of the audio signal using very narrow bandwidth filters. The magnitudes and phases of the corresponding sinusoidal basis functions  \n",
    "can be used to create an additive model of the sound. \n",
    "\n",
    "By careful use of windowing, overlap-add, and maintaining phase information one can achieve good sounding modifications such as pitch shifting and time scaling. \n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5923fcec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import IPython.display as ipd \n",
    "import sys\n",
    "import pyaudio\n",
    "import numpy as np\n",
    "import scipy\n",
    "from bokeh.io import output_notebook\n",
    "from bokeh.plotting import figure, output_file, show\n",
    "\n",
    "output_notebook()\n",
    "\n",
    "plot_library = 'matplotlib'\n",
    "#plot_library = 'matplotlib_xkcd'\n",
    "#plot_library = 'bokeh'\n",
    "\n",
    "\n",
    "if (plot_library=='bokeh'):\n",
    "    import bokeh \n",
    "    from bokeh.io import output_notebook\n",
    "    from bokeh.plotting import figure, output_file, show\n",
    "    output_notebook()\n",
    "\n",
    "    def plot(data_list): \n",
    "        p = figure(plot_height=300, plot_width=600, title='Synthesizers')\n",
    "        for data in data_list: \n",
    "            p.line(np.arange(0,len(data)), data)\n",
    "        show(p)\n",
    "        \n",
    "if (plot_library=='matplotlib'): \n",
    "    %matplotlib notebook \n",
    "    import matplotlib.pyplot as plt\n",
    "    def plot(data_list,label_list=[],xlabel='', ylabel='', title=''):\n",
    "        fig, ax = plt.subplots(figsize=(8,4))\n",
    "        for (data,label) in zip(data_list, label_list): \n",
    "            plt.title('Synth-CS: '+title)\n",
    "            plt.xlabel(xlabel)\n",
    "            plt.ylabel(ylabel)\n",
    "            plt.plot(np.arange(0, len(data)), data, label=label)\n",
    "        if (label_list):\n",
    "            ax.legend()\n",
    "        plt.ion()\n",
    "        plt.show()\n",
    "        \n",
    "if (plot_library=='matplotlib_xkcd'): \n",
    "    %matplotlib notebook \n",
    "    import matplotlib.pyplot as plt\n",
    "\n",
    "    def plot(data_list,label_list=[],xlabel='', ylabel='', title=''):\n",
    "        fig, ax = plt.subplots(figsize=(5,3))  \n",
    "        plt.xkcd()\n",
    "        if not(label_list):\n",
    "            for (i,d) in enumerate(data_list): \n",
    "                label_list.append(str(i))\n",
    "        for (data,label) in zip(data_list, label_list): \n",
    "            plt.title('Synth-CS: '+title)\n",
    "            plt.xlabel(xlabel)\n",
    "            plt.ylabel(ylabel)\n",
    "            plt.plot(np.arange(0, len(data)), data, label=label)  \n",
    "            ax.legend()\n",
    "        plt.ion()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c66514af",
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import IPython.display as ipd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5764db40",
   "metadata": {},
   "outputs": [],
   "source": [
    "y, sr = librosa.load(\"lpc_example.wav\")\n",
    "ipd.Audio(y, rate=sr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "193ba91b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def overlap_add_spectral(input, win_size, hop_size, mode=\"full\"): \n",
    "    # precompute the hanning window\n",
    "    window = scipy.signal.hann(win_size)\n",
    "    output= np.zeros(len(input)+win_size)   \n",
    "    phases = np.zeros(win_size)\n",
    "    mod_spectrum = np.zeros(win_size, dtype=complex)\n",
    "\n",
    "    for i in range(0,len(input)-win_size,hop_size):\n",
    "        # slice the audio into overlapping frames \n",
    "        frame = input[i:i+win_size]\n",
    "        # calculate the complex spectrum      \n",
    "        complex_spectrum =  np.fft.fft(window*frame)\n",
    "        \n",
    "        # convert to magnitude and phase \n",
    "        magnitudes = np.abs(complex_spectrum)\n",
    "        if (mode==\"full\"): \n",
    "            phases = np.angle(complex_spectrum)\n",
    "        elif  (mode=='random'):\n",
    "            phases = np.random.uniform(-np.pi, np.pi, size=win_size)\n",
    "\n",
    "        else: \n",
    "            phases = np.ones(win_size) * np.pi\n",
    "       \n",
    "        # back to real and imaginare \n",
    "        mod_spectrum.real, mod_spectrum.imag = (np.cos(phases), \n",
    "                                                np.sin(phases)) * magnitudes\n",
    "        \n",
    "        \n",
    "        # go back to the time domain from the complex spectrum \n",
    "        reconstructed_frame = np.fft.ifft(mod_spectrum).real\n",
    "        \n",
    "        if (i == 10 * hop_size): \n",
    "            plot([window *frame, reconstructed_frame], ['frame', 'reco'])\n",
    "        \n",
    "        if len(frame)==win_size:\n",
    "            output[i:i+win_size] += reconstructed_frame        \n",
    "    return 0.5 * output    \n",
    "\n",
    "output = overlap_add_spectral(y, 2048, 512, \"random\")\n",
    "ipd.Audio(output, rate=sr, normalize=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92da0a22",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = overlap_add_spectral(y, 2048, 512, \"zeros\")\n",
    "ipd.Audio(output, rate=sr, normalize=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1699c394",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = overlap_add_spectral(y, 2048, 512, \"random\")\n",
    "ipd.Audio(output, rate=sr, normalize=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "571e6eaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def overlap_add_time_stretch(input, win_size, hop_size, mode=\"full\", time_scale = 2.0): \n",
    "    # precompute the hanning window\n",
    "    window = scipy.signal.hann(win_size)\n",
    "    output= np.zeros(int(time_scale * len(input)+win_size))   \n",
    "    phases = np.zeros(win_size)\n",
    "    mod_spectrum = np.zeros(win_size, dtype=complex)\n",
    "    ana_hop_size = int(hop_size/time_scale)\n",
    "    syn_hop_size = hop_size \n",
    "    frame = np.zeros(win_size)\n",
    "    \n",
    "    k = 0 \n",
    "    for i in range(0,len(input)-win_size,ana_hop_size):\n",
    "        # slice the audio into overlapping frames \n",
    "        frame = input[i:i+win_size]\n",
    "        # calculate the complex spectrum      \n",
    "        complex_spectrum =  np.fft.fft(window*frame)\n",
    "        \n",
    "        # convert to magnitude and phase \n",
    "        magnitudes = np.abs(complex_spectrum)\n",
    "        if (mode==\"full\"): \n",
    "            phases = np.angle(complex_spectrum)\n",
    "        elif  (mode=='random'):\n",
    "            phases = np.random.uniform(-np.pi, np.pi, size=win_size)\n",
    "\n",
    "        else: \n",
    "            phases = np.zeros(win_size)\n",
    "       \n",
    "        # back to real and imaginare \n",
    "        mod_spectrum.real, mod_spectrum.imag = (np.cos(phases), np.sin(phases)) * magnitudes\n",
    "        \n",
    "        # go back to the time domain from the complex spectrum \n",
    "        reconstructed_frame = np.fft.ifft(mod_spectrum).real\n",
    "        \n",
    "        \n",
    "        if len(output[k:k+win_size])==win_size:\n",
    "             output[k:k+win_size] += reconstructed_frame \n",
    "        k += syn_hop_size \n",
    "            \n",
    "    return 0.5 * output    \n",
    "\n",
    "output = overlap_add_time_stretch(y, 2048, 512, \"zero\", time_scale=0.5)\n",
    "ipd.Audio(output, rate=sr, normalize=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1841f80",
   "metadata": {},
   "outputs": [],
   "source": [
    "def phasevocoder(input, win_size, hop_size, time_scale = 2.0, mode=\"delta\"): \n",
    "    # precompute the hanning window\n",
    "    window = scipy.signal.hann(win_size)\n",
    "    output= np.zeros(int(time_scale * len(input)+win_size))   \n",
    "    phases = np.zeros(win_size)\n",
    "    accum_phases = np.zeros(win_size)\n",
    "    mod_spectrum = np.zeros(win_size, dtype=complex)\n",
    "    ana_hop_size = int(hop_size/time_scale)\n",
    "    syn_hop_size = hop_size \n",
    "    frame = np.zeros(win_size)\n",
    "    phase_differences = np.zeros(win_size)\n",
    "    prev_complex_spectrum = np.zeros(win_size, dtype=complex)\n",
    "    k = 0 \n",
    "    prev_phases = np.zeros(win_size)\n",
    "    \n",
    "    for i in range(0,len(input)-2*win_size,ana_hop_size):\n",
    "        # slice the audio into overlapping frames \n",
    "        frame = input[i:i+win_size]        \n",
    "        # calculate the complex spectrum      \n",
    "        complex_spectrum =  np.fft.fft(window*frame)\n",
    "        magnitudes = np.abs(complex_spectrum)\n",
    "        phases = np.angle(complex_spectrum)\n",
    "        delta_phases = phases - prev_phases\n",
    "        prev_phases = np.copy(phases)\n",
    "        delta_phases = np.unwrap(delta_phases)\n",
    "        \n",
    "        if (mode == 'delta'): \n",
    "            # take their phase difference and integrate\n",
    "            # bring the phase back to between pi and -pi   (phase unwarping)\n",
    "            accum_phases += delta_phases \n",
    "        elif mode == 'original': \n",
    "            phases = np.angle(complex_spectrum)\n",
    "        elif mode == 'random': \n",
    "            phases = np.random.uniform(-np.pi, np.pi, size=win_size)\n",
    "\n",
    "        # back to real and imaginary \n",
    "        mod_spectrum.real, mod_spectrum.imag = (np.cos(accum_phases), np.sin(accum_phases)) * magnitudes\n",
    "        \n",
    "        # go back to the time domain from the complex spectrum \n",
    "        reconstructed_frame = np.fft.ifft(mod_spectrum).real\n",
    "        \n",
    "        if len(output[k:k+win_size])==win_size:\n",
    "             output[k:k+win_size] += reconstructed_frame \n",
    "                \n",
    "        prev_complex_spectrum = np.copy(complex_spectrum)\n",
    "        k += syn_hop_size \n",
    "            \n",
    "    return 0.5 * output    \n",
    "\n",
    "\n",
    "#pitch_ratio = 5.0/4.0 \n",
    "pitch_ratio = 4.0/5.0\n",
    "\n",
    "output = phasevocoder(y, 2048, 512, time_scale=1.0/pitch_ratio, mode='delta')\n",
    "ipd.Audio(output, rate=sr, normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3192c73b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import resampy\n",
    "pitch_shifted = resampy.resample(output,sr, sr * pitch_ratio)\n",
    "ipd.Audio(pitch_shifted, rate=sr, normalize=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "035890e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# just time stretch \n",
    "output = phasevocoder(y, 2048, 512, time_scale=1.25 )\n",
    "ipd.Audio(output, rate=sr, normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e8c3902",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pitch shift with resampling "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37af9858",
   "metadata": {},
   "outputs": [],
   "source": [
    "import resampy\n",
    "pitch_shifted = resampy.resample(y,sr, sr * pitch_ratio)\n",
    "ipd.Audio(pitch_shifted, rate=sr, normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac81e811",
   "metadata": {},
   "outputs": [],
   "source": [
    "y, sr = librosa.load(\"disco.00000.wav\")\n",
    "ipd.Audio(y, rate=sr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ef19aec",
   "metadata": {},
   "outputs": [],
   "source": [
    "pitch_ratio = 5.0/4.0\n",
    "output = phasevocoder(y, 2048, 512, time_scale=1.0/pitch_ratio)\n",
    "ipd.Audio(output, rate=sr, normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6253f19",
   "metadata": {},
   "outputs": [],
   "source": [
    "import resampy\n",
    "pitch_shifted = resampy.resample(output,sr, sr * pitch_ratio)\n",
    "ipd.Audio(pitch_shifted, rate=sr, normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08e50647",
   "metadata": {},
   "outputs": [],
   "source": [
    "def phasevocoder(input, win_size, hop_size, time_scale = 2.0, mode=\"delta\", num_sinusoids=100): \n",
    "    # precompute the hanning window\n",
    "    window = scipy.signal.hann(win_size)\n",
    "    output= np.zeros(int(time_scale * len(input)+win_size))   \n",
    "    phases = np.zeros(win_size)\n",
    "    accum_phases = np.zeros(win_size)\n",
    "    mod_spectrum = np.zeros(win_size, dtype=complex)\n",
    "    ana_hop_size = int(hop_size/time_scale)\n",
    "    syn_hop_size = hop_size \n",
    "    frame = np.zeros(win_size)\n",
    "    phase_differences = np.zeros(win_size)\n",
    "    prev_complex_spectrum = np.zeros(win_size, dtype=complex)\n",
    "    k = 0 \n",
    "    prev_phases = np.zeros(win_size)\n",
    "    \n",
    "    for i in range(0,len(input)-2*win_size,ana_hop_size):\n",
    "        # slice the audio into overlapping frames \n",
    "        frame = input[i:i+win_size]        \n",
    "        # calculate the complex spectrum      \n",
    "        complex_spectrum =  np.fft.fft(window*frame)\n",
    "        magnitudes = np.abs(complex_spectrum)\n",
    "        phases = np.angle(complex_spectrum)\n",
    "        delta_phases = phases - prev_phases\n",
    "        prev_phases = np.copy(phases)\n",
    "        delta_phases = np.unwrap(delta_phases)\n",
    "\n",
    "        \n",
    "        mag_threshold = np.sort(magnitudes)[-num_sinusoids]\n",
    "        low_value_bins = magnitudes < mag_threshold  # Where values are low\n",
    "        #print('low value bins', low_value_bins)\n",
    "        magnitudes[low_value_bins] = 0 # set to zero \n",
    "        \n",
    "        if (mode == 'delta'): \n",
    "            # take their phase difference and integrate\n",
    "            # bring the phase back to between pi and -pi   (phase unwarping)\n",
    "            accum_phases += delta_phases \n",
    "        elif mode == 'original': \n",
    "            phases = np.angle(complex_spectrum)\n",
    "        elif mode == 'random': \n",
    "            phases = np.random.uniform(-np.pi, np.pi, size=win_size)\n",
    "\n",
    "        # back to real and imaginary \n",
    "        mod_spectrum.real, mod_spectrum.imag = (np.cos(accum_phases), np.sin(accum_phases)) * magnitudes\n",
    "        \n",
    "        # go back to the time domain from the complex spectrum \n",
    "        reconstructed_frame = np.fft.ifft(mod_spectrum).real\n",
    "        \n",
    "        if len(output[k:k+win_size])==win_size:\n",
    "             output[k:k+win_size] += reconstructed_frame \n",
    "                \n",
    "        prev_complex_spectrum = np.copy(complex_spectrum)\n",
    "        k += syn_hop_size \n",
    "            \n",
    "    return 0.5 * output    \n",
    "\n",
    "\n",
    "pitch_ratio = 2.0/4.0 \n",
    "#pitch_ratio = 4.0/5.0\n",
    "\n",
    "output = phasevocoder(y, 2048, 512, time_scale=1.0/pitch_ratio, mode='delta', num_sinusoids=2000)\n",
    "ipd.Audio(output, rate=sr, normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dde25beb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79fcf23f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00c962d8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
